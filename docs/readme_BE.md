## Лематызатар ЭКБМ: агульныя звесткі ##

У гэтым рэпазіторыі знаходзіцца лематызатар, які быў створаны ў 2013 годзе ў межах праекта &laquo;Эксперыментальны корпус беларускай мовы&raquo; (<i>Yet Another Belorussian Corpus</i>, гл. яго [старонку](https://github.com/poritski/YABC)). Лематызатар з'яўляецца правілавым, у яго аснову пакладзены Граматычны слоўнік беларускай мовы, тамы якога можна знайсці на сайце slounik.org ([назоўнік](http://www.slounik.org/nazounik), [дзеяслоў](http://www.slounik.org/dzsl), [астатнія часціны мовы](http://www.slounik.org/prym)).

## Падрыхтоўка да выкарыстання ##

Спампуйце [ZIP-архіў з файламі праекта](https://github.com/poritski/YABC_Tagger/archive/master.zip) і распакуйце яго ў адвольнае месца на сваёй лакальнай машыне. Каб карыстацца лематызатарам, вам будзе патрэбен інтэрпрэтатар [Perl](http://www.activestate.com/activeperl/downloads) 5.x (лепш за ўсё 5.10 ці больш новы) з інсталяванымі модулямі [`Array::Utils`](http://search.cpan.org/dist/Array-Utils/Utils.pm), [`List::Util`](http://search.cpan.org/~pevans/Scalar-List-Utils-1.31/lib/List/Util.pm) і [`Benchmark`](http://search.cpan.org/~rjbs/perl-5.18.1/lib/Benchmark.pm). Праграма распрацавана пад аперацыйную сістэму Windows, але карыстальнікі Unix-падобных сістэм не павінны сутыкнуцца з вялікімі цяжкасцямі пры падрыхтоўцы лематызатара да працы.

## Параметры каманднага радка ##

Лематызатар запускаецца з каманднага радка і прымае наступныя параметры:

* `-i [шлях да файла]` – адзіны абавязковы параметр: уваходны тэкставы файл на беларускай мове. Папярэдне тэкст трэба такенізаваць так, каб апісанне кожнага токена размяшчалася на асобным радку. Што тычыцца тэхнічных асаблівасцей, гэта павінен быць TSV-файл з любой колькасцю слупкоў, апошні з якіх змяшчае сам токен; увогуле, слупок можа быць і адзін. Для такенізацыі можна карыстацца, напрыклад, скрыптом Г. Шміда з праекта [TreeTagger](http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger) з нашым дадаткам `preprocessor.pl`. Абедзве гэтыя праграмы ўтрымліваюцца ў рэпазіторыі.

* `-c [лічба]` – колькасць слупкоў ва ўваходным файле. Па змоўчанні яна прымаецца роўнай 3: ідэнтыфікатар тэкставага фрагмента - парадкавы нумар токена ў ім - сам токен.

* `-o [шлях да файла]` – выхадны файл. Па змоўчанні вынік лематызацыі друкуецца ў файл, імя якога адрозніваецца ад імені ўваходнага файла толькі прэфіксам `tagged_`. Гэта таксама TSV-файл, але слупкоў ў ім на два больш, чым ва ўваходным (дадаюцца лемы і граматычныя звесткі).

* `-u [шлях да файла]` – файл з інфармацыяй пра токены, якія падалося немагчымым апазнаць. Па змоўчанні яна друкуецца ў файл, імя якога адрозніваецца ад імені ўваходнага файла прэфіксам `unknown_`.

* `-m [bnkorpus|multext_east]` – маска тэгсэта. Па змоўчанні выкарыстоўваецца [тэгсэт ЭКБМ](http://htmlpreview.github.io/?https://github.com/poritski/YABC_Tagger/blob/master/docs/tagset_YABC_BE.html). Пры выстаўленай опцыі `-m bnkorpus` тэгі вяртаюцца ў фармаце [граматычнай базы У. А. Кошчанкі](http://bnkorpus.info/download.html), аднак, некалькі адаптаваным (гл. [падрабязнасці](http://htmlpreview.github.io/?https://github.com/poritski/YABC_Tagger/blob/master/docs/tagset_bnkorpus_BE.html)). Калі будуць устаноўлены адпаведнасці паміж тэгсэтам ЭКБМ і [MulTEXT East](http://nl.ijs.si/ME/Vault/V3/msd/html), уключыць гэтую маску можна будзе пры дапамозе опцыі `-m multext_east`.

## Прыклад выкарыстання ##

Пакажам увесь цыкл падрыхтоўкі і граматычнай анатацыі тэкстаў на прыкладзе, які карыстальнік можа паўтарыць самастойна. У дырэкторыі `./raw/` знаходзяцца дзве групы тэкстаў: 100 артыкулаў з газеты &laquo;Звязда&raquo; (`./raw/zviazda_sample/`) і дзве аповесці Максіма Гарэцкага (`./raw/Harecki/`). Іх неабходна такенізаваць і лематызаваць.

1. Створым файл `dirlist.txt`, у якім на асобных радках змешчаны толькі назвы паддырэкторый (абсалютны шлях да іх прыводзіць не трэба, г. зн. проста `zviazda_sample` і `Harecki`). Створым аднайменныя паддырэкторыі у папцы `./tokenized/`. (У якасці ўзору гэта ўжо зроблена.)
2. Запусцім скрыпт `preprocessor.pl`. У паддырэкторыях `./tokenized/zviazda_sample/` і `./tokenized/Harecki/` з'явяцца такенізаваныя файлы.
3. Запусцім скрыпт `conjoiner.pl`. У асноўнай дырэкторыі будуць створаны файлы `corpus.txt` і `corpus_fileid.txt`. Першы з іх - гэта TSV-файл у тры слупкі, вынік аб'яднання такенізаваных тэкстаў. Другі – гэта табліца, у якой зафіксаваны пары кшталту &laquo;лічбавы ідэнтыфікатар файла – яго першапачатковае імя&raquo;.
4. Запусцім лематызатар з каманднага радка:<br>
   <span style="padding-left: 3em">`perl tagger.pl -i corpus.txt`</span><br>
У асноўнай дырэкторыі з'явяцца файлы `tagged_corpus.txt` (вынік лематызацыі) і `unknown_corpus.txt` (спіс &laquo;невядомых&raquo; токенаў). Кансольны вывад будзе выглядаць прыблізна так:<br>
<span style="padding-left: 3em">`Reading database...`</span><br>
<span style="padding-left: 3em">`Complete in 9.42 seconds.`</span><br>
<span style="padding-left: 3em">`Processing input...`</span><br>
<span style="padding-left: 3em">`Complete in 1.16 seconds.`</span><br>
<span style="padding-left: 3em">`110762 tokens in total, 106331 tokens processed (0.9600).`</span><br>
<span style="padding-left: 3em">`Recognized at once: 92044 (0.8310).`</span><br>
<span style="padding-left: 3em">`2nd level gain: 14175 (0.1280).`</span><br>
<span style="padding-left: 3em">`3rd level gain: 0 (0.0000).`</span><br>
<span style="padding-left: 3em">`4th level gain: 112 (0.0010).`</span><br>
<span style="padding-left: 3em">`Press any key to exit.`</span><br>
Як бачым, уваходны корпус змяшчае каля 110 тыс. токенаў, 96% з якіх распазнаюцца лематызатарам. Сэнс астатніх запісаў будзе патлумачаны ў наступных параграфах.

## Некаторыя дэталі рэалізацыі ##

Сам лематызатар складаецца з файла дадзеных `./base/db.txt` і скрыпта `tagger.pl`. Скрыпт узнаўляе з файла дадзеных дзве хэш-табліцы: лем і граматычных тэгаў. Сістэма апрацоўкі ўваходнага тэкста прадугледжвае, што токен можа &laquo;знайсціся&raquo; у файле дадзеных:

* Адразу, г. зн. у такім жа выглядзе, як і ў тэксце.
* Пасля тэхнічнай нармалізацыі: замены _ў_ на _у_ у пачатку слова і лацінскага _i_ на беларускае там, дзе ў гэтым ёсць неабходнасць.
* Пасля арфаграфічнай нармалізацыі: выдалення _ь_ у кантэкстных умовах, якія прадугледжвае [&laquo;дзеясловіца&raquo;](https://be-x-old.wikipedia.org/wiki/Дзеясловіца). Лематызатар &laquo;ведае&raquo; толькі гэту асаблівасць [Беларускага класічнага правапісу](https://be-x-old.wikipedia.org/wiki/Беларускі_клясычны_правапіс).
* Пасля выдалення злучка пры пераносе.
* Пасля падзелу па злучку на дзве ці тры самастойныя часткі (выпадак складанага назоўніка, падвоенага дзеяслова і г. д.).
* У любым з папярэдніх варыянтаў з прывядзеннем да ніжняга рэгістра.

Акрамя таго, токен можа трапіць у адзін з класаў, якія апазнаюцца regex-шаблонамі: слова лацінскімі літарамі, рускае слова, ініцыял імені, цэлы лік у запісе арабскімі ці рымскімі лічбамі, дзесятковы дроб, час, дата, лік у гульні, парадкавы нумар у спісе і г. д.

З улікам таго, як часта кожная з пазначаных вышэй сітуацый можа ўзнікаць пры граматычным аналізе мастацкіх і газетных тэкстаў, апрацоўка падзяляецца на чатыры &laquo;узроўні&raquo; ці &laquo;крокі&raquo;:

1. Токен у першапачатковым выглядзе (+ прыведзены да ніжняга рэгістра).
2. Тэхнічна нармалізаваны токен (+ прыведзены да ніжняга рэгістра). Шаблоны.
3. Арфаграфічна нармалізаваны токен (+ прыведзены да ніжняга рэгістра).
4. Выдаленне злучка ці падзел па ім.

Пераход да кожнага наступнага ўзроўня адбываецца толькі тады, калі на папярэднім кроку токен не быў апазнаны. Калі ўсе магчымасці былі правераны і засталіся беспаспяховымі, вяртаецца граматычны тэг `UNK` і лема, што супадае з зыходным токенам, да якога далучаны злева пытальнік.

Фрагмент кансольнага вываду, змешчаны вышэй, паказвае, што ў 100 артыкулах &laquo;Звязды&raquo; і дзвюх аповесцях Гарэцкага 83.1% токенаў былі распазнаны адразу, 12.8% – пасля тэхнічнай нармалізацыі ці супастаўлення з шаблонамі. Наступныя крокі амаль не павялічылі прадукцыйнасць, таму што тэксты набраны &laquo;наркамаўкай&raquo; і змяшчаюць мала словаформ, напісаных праз злучок.

Файл дадзеных фіксуе некаторыя арфаграфічныя варыянты, якія ўзніклі пасля рэформы 2008 г. (<i>пяцьдзесят</i> / <i>пяцьдзясят</i> і г. д.). У такіх выпадках выкарыстоўваецца тэг `[ORTH]` ці `[ORTH=нарматыўнае напісанне]`, што далучаецца да лемы справа. &laquo;Дзеясловіцу&raquo;, калі яна адрозніваецца ад афіцыйнай нормы, лематызатар пазначае тэгам `[TAR]`.

## Хуткадзейнасць і якасць разбору ##

Лематызатар ЭКБМ у яго цяперашнім выглядзе пажадана выкарыстоўваць для аналізу вялікіх тэкставых калекцый (да дзесяткаў млн токенаў), папярэдне аб'яднаных у адзін файл. Апрацоўваць з яго дапамогай маленькія дакументы не вельмі зручна, таму што праграма грузіць у памяць файл дадзеных `db.txt` пры кожным запуску. На камп'ютары аднаго з распрацоўшчыкаў (2 ГГц CPU, 3 Гб RAM, WinXP SP3) для гэтага патрабуецца прыкладна 9.5 секунд; пры маскіроўцы тэгсэта выдаткі часу яшчэ павялічваюцца.

Хуткасць выканання граматычнага разбору залежыць ад уласцівасцей уваходнага тэкста (якасць друку і / ці вычыткі, колькасць &laquo;дзеясловічных&raquo; напісанняў і г. д.). Калекцыі тэкстаў, што былі намі падрыхтаваны і разгледжаны, аналізаваліся з хуткасцю каля 100 тыс. токенаў за секунду. Падрабязная статыстыка падаецца ў наступнай табліцы:

<center>
<table>
<tr align="center"><td>Падкорпус</td><td>Час</td><td>Усяго токенаў</td><td>Апазнана</td><td>Крок 1</td><td>Крок 2</td><td>Крок 3</td><td>Крок 4</td></tr>
<tr><td>&laquo;Голас Радзімы&raquo;</td><td>4.05</td><td>417550</td><td>406725 = 97.41%</td><td>384707</td><td>20995</td><td>11</td><td>1012</td></tr>
<tr><td>&laquo;Чырвоная змена&raquo;</td><td>3.87</td><td>375269</td><td>368920 = 98.38%</td><td>278470</td><td>90207</td><td>0</td><td>243</td></tr>
<tr><td>&laquo;Звязда&raquo;</td><td>28.19</td><td>2481775</td><td>2432989 = 98.03%</td><td>1792116</td><td>639152</td><td>7</td><td>1714</td></tr>
<tr><td>&laquo;Маладосць&raquo;</td><td>8.84</td><td>1022215</td><td>1004368 = 98.25%</td><td>976369</td><td>27029</td><td>0</td><td>970</td></tr>
<tr><td>&laquo;Полымя&raquo;</td><td>9.66</td><td>1059707</td><td>1038559 = 98.00%</td><td>1007046</td><td>30457</td><td>2</td><td>1054</td></tr>
<tr><td>&laquo;Дзеяслоў&raquo;</td><td>7.98</td><td>790798</td><td>768107 = 97.13%</td><td>729993</td><td>25286</td><td>11697</td><td>1131</td></tr>
<tr><td>Старая проза</td><td>6.48</td><td>728462</td><td>712743 = 97.84%</td><td>686082</td><td>25957</td><td>1</td><td>703</td></tr>
</table>
</center>

Як можна пабачыць, найбольш павольна аналізаваліся артыкулы з газеты &laquo;Звязда&raquo; і дадатка да яе &laquo;Чырвоная змена&raquo; (88 і 97 тыс. токенаў за секунду). Гэта тлумачыцца нізкай якасцю набору - недарэчным выкарыстанне лацінскага _i_, пар. колькасць токенаў, апазнаных на другім кроку: 25.7% і 24.0% пры менш за 5% ва ўсіх астатніх падкорпусах. Адносна павольна (99 тыс. токенаў за секунду) аналізаваліся тэксты з часопіса &laquo;Дзеяслоў&raquo;, што звязана з яго арфаграфічнымі асаблівасцямі, пар. колькасць токенаў, апазнаных на трэцім кроку: 1.5% пры досыць нязначнай колькасці ва ўсіх астатніх падкорпусах.

Ахоп тэкставага матэрыялу ў разгледжаных намі калекцыях у сярэднім не ніжэй за 97%. У асобных фрагментах якасць можа быць горшай з-за наяўнасці там уласных імёнаў, што адсутнічаюць у базе, перадачы дыялектнай ці іншамоўнай гаворкі і г. д.

## Умовы выкарыстання ##

Лематызатар распаўсюджваецца пад BSD-падобнай ліцэнзіяй з 2 пунктаў, гл. яе тэкст [на рускай мове](license_RU.md) ці [на англійскай мове](license_EN.md). Пры выкарыстанні праграмы пажадана (але неабавязкова) спасылацца на сайт [slounik.org](http://www.slounik.org), распрацоўшчыкі якога выклалі ў сеціва Граматычны слоўнік беларускай мовы, і на [старонку](https://github.com/poritski/YABC_Tagger) нашага праекта.